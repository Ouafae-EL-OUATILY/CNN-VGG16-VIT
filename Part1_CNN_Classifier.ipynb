{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epZ2TlEkzAfv",
        "outputId": "ae33ff32-242a-4661-bb5d-8fa9b1711a9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_3FX7fXwTL2",
        "outputId": "6e5f2006-f810-4122-a060-13eb2a4afc8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/kaggle/api/kaggle_api_extended.py\", line 403, in authenticate\n",
            "    raise IOError('Could not find {}. Make sure it\\'s located in'\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!kaggle datasets download -d hojjatk/mnist-dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gnb9Bke61hKV",
        "outputId": "3cdf2713-a276-4596-f395-a9d46b82501d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Downloading pyarrow_hotfix-0.5-py3-none-any.whl (7.8 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.15.0 dill-0.3.7 multiprocess-0.70.15 pyarrow-hotfix-0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_csv_path = \"/content/sample_data/mnist_train_small.csv\"\n",
        "test_csv_path = \"/content/sample_data/mnist_test.csv\"\n",
        "\n",
        "# Load CSV files into Pandas DataFrames\n",
        "train_df = pd.read_csv(train_csv_path)\n",
        "test_df = pd.read_csv(test_csv_path)\n",
        "\n",
        "# information about the DataFrames\n",
        "print(\"Training set shape:\", train_df.shape)\n",
        "print(\"Test set shape:\", test_df.shape)\n",
        "\n",
        "# first rows of DataFrames\n",
        "print(\"\\nTraining set:\")\n",
        "print(train_df.head())\n",
        "\n",
        "print(\"\\nTest set:\")\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFBhMs7623tU",
        "outputId": "683b2ee9-ed37-4421-e685-4b3d86b35c62"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (19999, 785)\n",
            "Test set shape: (9999, 785)\n",
            "\n",
            "Training set:\n",
            "   6  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.581  0.582  0.583  \\\n",
            "0  5  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "1  7  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "2  9  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "3  5  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "4  2  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "\n",
            "   0.584  0.585  0.586  0.587  0.588  0.589  0.590  \n",
            "0      0      0      0      0      0      0      0  \n",
            "1      0      0      0      0      0      0      0  \n",
            "2      0      0      0      0      0      0      0  \n",
            "3      0      0      0      0      0      0      0  \n",
            "4      0      0      0      0      0      0      0  \n",
            "\n",
            "[5 rows x 785 columns]\n",
            "\n",
            "Test set:\n",
            "   7  0  0.1  0.2  0.3  0.4  0.5  0.6  0.7  0.8  ...  0.658  0.659  0.660  \\\n",
            "0  2  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "1  1  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "2  0  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "3  4  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "4  1  0    0    0    0    0    0    0    0    0  ...      0      0      0   \n",
            "\n",
            "   0.661  0.662  0.663  0.664  0.665  0.666  0.667  \n",
            "0      0      0      0      0      0      0      0  \n",
            "1      0      0      0      0      0      0      0  \n",
            "2      0      0      0      0      0      0      0  \n",
            "3      0      0      0      0      0      0      0  \n",
            "4      0      0      0      0      0      0      0  \n",
            "\n",
            "[5 rows x 785 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MNISTDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label = torch.tensor(self.dataframe.iloc[idx, 0], dtype=torch.long)\n",
        "        image = torch.tensor(self.dataframe.iloc[idx, 1:].values, dtype=torch.float32).view(1, 28, 28)  # Add the channel dimension\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Transformation\n",
        "transform = transforms.Compose([transforms.Normalize((0.5,), (0.5,))])\n",
        "\n",
        "# Create instances from MNISTDataset\n",
        "train_dataset = MNISTDataset(train_df, transform=transform)\n",
        "test_dataset = MNISTDataset(test_df, transform=transform)\n",
        "\n",
        "# DataLoaders\n",
        "batch_size = 64  #only for a batch\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "oe5EqS6U34By"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Display some images from the dataset\n",
        "def show_images(images, labels, nrows=1, ncols=5):\n",
        "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, 3))\n",
        "    for i, ax in enumerate(axes.flatten()):\n",
        "        ax.imshow(images[i].view(28, 28), cmap='gray')\n",
        "        ax.set_title(f\"Label: {labels[i]}\")\n",
        "        ax.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of images and labels\n",
        "for images, labels in train_loader:\n",
        "    show_images(images, labels)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "VOM8rkdEXUzR",
        "outputId": "cd787011-4eaa-4edb-de74-8d3701874148"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the CNN architecture\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(128, 10)  # 10 classes for digits 0-9\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)  # Flatten before fully connected layers\n",
        "        x = self.relu3(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "learning_rate = 0.0001\n",
        "epochs = 20\n",
        "\n",
        "# Create DataLoader for training and testing datasets (assumed)\n",
        "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "# test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Initialize the CNN model\n",
        "model = CNN().to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_losses = []\n",
        "\n",
        "# Training the model\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # Calculate and store the average training loss for the epoch\n",
        "    average_loss = running_loss / len(train_loader)\n",
        "    train_losses.append(average_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {average_loss}\")\n",
        "\n",
        "# Testing the model\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)  # Move data to GPU\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = correct / total\n",
        "print(f\"Accuracy on the test set: {100 * accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbgEJX7mLLfE",
        "outputId": "20e96995-6774-4539-e163-046f34c88c0c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20, Loss: 0.8080099511284607\n",
            "Epoch 2/20, Loss: 0.16965334762792333\n",
            "Epoch 3/20, Loss: 0.09656743679534846\n",
            "Epoch 4/20, Loss: 0.06340022416995131\n",
            "Epoch 5/20, Loss: 0.040437575440743\n",
            "Epoch 6/20, Loss: 0.028997994935852825\n",
            "Epoch 7/20, Loss: 0.0215172850010439\n",
            "Epoch 8/20, Loss: 0.023539109667409776\n",
            "Epoch 9/20, Loss: 0.021705404350898762\n",
            "Epoch 10/20, Loss: 0.014375014684304415\n",
            "Epoch 11/20, Loss: 0.00498950664306334\n",
            "Epoch 12/20, Loss: 0.005173280040253303\n",
            "Epoch 13/20, Loss: 0.014079867119424529\n",
            "Epoch 14/20, Loss: 0.02177940867275207\n",
            "Epoch 15/20, Loss: 0.011261485262942902\n",
            "Epoch 16/20, Loss: 0.004926373731716315\n",
            "Epoch 17/20, Loss: 0.0076085406401852525\n",
            "Epoch 18/20, Loss: 0.013263279750233302\n",
            "Epoch 19/20, Loss: 0.008649969598388508\n",
            "Epoch 20/20, Loss: 0.012207659709046087\n",
            "Accuracy on the test set: 98.04%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'cnn_model.pth')"
      ],
      "metadata": {
        "id": "pVcLJOKEjT_H"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "# Load the saved model\n",
        "model = CNN()\n",
        "model.load_state_dict(torch.load('cnn_model.pth'))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "new_image_path = '/content/neuf.png'\n",
        "new_image = Image.open(new_image_path).convert(\"L\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "new_image = transform(new_image)\n",
        "new_image = new_image.unsqueeze(0)\n",
        "\n",
        "with torch.no_grad():\n",
        "    new_image = new_image.to(device)\n",
        "    outputs = model(new_image)\n",
        "    _, predicted_class = torch.max(outputs, 1)\n",
        "\n",
        "print(f\"Predicted Class: {predicted_class.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Jn2bJ8NJaa6",
        "outputId": "7bfaeff4-6325-4e74-c956-75d2608ca928"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Di2FbNnLbTx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}